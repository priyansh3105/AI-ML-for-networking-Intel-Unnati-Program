import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib

# ğŸ“‚ Load the dataset
df = pd.read_csv("traffic.csv")

# ğŸ§¾ Print column names
print("ğŸ“‹ Columns in dataset:", df.columns.tolist())

# ğŸ› ï¸ Preprocessing
label_column = 'Label (0 = Unencrypted, 1 = Encrypted)'
X = df.drop(label_column, axis=1)
y = df[label_column]

# Convert categorical features to numeric using one-hot encoding
X = pd.get_dummies(X)

# ğŸ“š Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ¤– Train the model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ğŸ“Š Feature importance visualization
importances = model.feature_importances_
feature_names = X.columns
sorted_indices = importances.argsort()[::-1]

plt.figure(figsize=(10, 6))
plt.title("ğŸ” Feature Importance")
plt.bar(range(len(importances)), importances[sorted_indices], align="center")
plt.xticks(range(len(importances)), feature_names[sorted_indices], rotation=45, ha='right')
plt.tight_layout()
plt.savefig("feature_importance.png")
plt.show()

# ğŸ§ª Evaluate model
y_pred = model.predict(X_test)
print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
print("\nğŸ“„ Classification Report:\n", classification_report(y_test, y_pred))

# ğŸ’¾ Save the model
joblib.dump(model, "traffic_model.joblib")
print("âœ… Model saved as traffic_model.joblib")